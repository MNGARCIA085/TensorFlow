{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf549d1",
   "metadata": {},
   "source": [
    "# <center> <font color='#0B5345'> <b> Predefined callbacks </font> </b> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdf7cff",
   "metadata": {},
   "source": [
    "### <b> <font color='blue'> Table of Contents </b> </font>\n",
    "\n",
    "- 1. [Libraries](#1)\n",
    "- 2. [Loading data](#2)\n",
    "- 3. [Model Building](#3)\n",
    "- 4. [Training with callbacks](#4)\n",
    "   - 4.1. [Early Stopping](#4.1)\n",
    "   - 4.2. [Learning Rate Scheduler](#4.2)\n",
    "   - 4.3. [Tensor Board](#4.3)\n",
    "   - 4.4. [Checkpoint](#4.4)\n",
    "   - 4.5. [Combining callbacks](#4.5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3bbc5",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## <b> <font color='##138D75'> 1. Libraries </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06922257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que no se impriman info y warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import warnings\n",
    "# Ignore specific warning\n",
    "warnings.filterwarnings('ignore', message='Allocation of .* exceeds 10% of free system memory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea98ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks, models\n",
    "from tensorflow.keras.models import load_model\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30afffed",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## <b> <font color='##138D75'> 2. Loading data </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee833e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Load data into training and testing sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36e034",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## <b> <font color='##138D75'> 3. Model building </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2826a12",
   "metadata": {},
   "source": [
    "Let's create a simple model (our goal here is to learn about callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e7a5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "        tf.keras.layers.Dense(10),\n",
    "        tf.keras.layers.Dense(10,activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bcee7c",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## <b> <font color='##138D75'> 4. Training with Early Stopping callback </b> </font>\n",
    "\n",
    "<a name=\"4.1\"></a>\n",
    "### 4.1. Early Stopping\n",
    "\n",
    "The \"Early Stopping Callback\" stops training when a monitored metric has stopped improving.\n",
    "\n",
    "It is a way to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2254036",
   "metadata": {},
   "source": [
    "First, let's use the \"bad model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5f4b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c443225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4464 - accuracy: 0.8782 - val_loss: 0.2987 - val_accuracy: 0.9175\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2941 - accuracy: 0.9168 - val_loss: 0.2785 - val_accuracy: 0.9202\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2786 - accuracy: 0.9218 - val_loss: 0.2739 - val_accuracy: 0.9241\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2708 - accuracy: 0.9254 - val_loss: 0.2771 - val_accuracy: 0.9252\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2653 - accuracy: 0.9263 - val_loss: 0.2748 - val_accuracy: 0.9237\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2612 - accuracy: 0.9277 - val_loss: 0.2725 - val_accuracy: 0.9235\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2583 - accuracy: 0.9288 - val_loss: 0.2783 - val_accuracy: 0.9211\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2561 - accuracy: 0.9290 - val_loss: 0.2710 - val_accuracy: 0.9248\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2541 - accuracy: 0.9296 - val_loss: 0.2693 - val_accuracy: 0.9239\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2523 - accuracy: 0.9303 - val_loss: 0.2670 - val_accuracy: 0.9272\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2513 - accuracy: 0.9302 - val_loss: 0.2735 - val_accuracy: 0.9236\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2491 - accuracy: 0.9312 - val_loss: 0.2826 - val_accuracy: 0.9245\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2480 - accuracy: 0.9312 - val_loss: 0.2763 - val_accuracy: 0.9243\n",
      "313/313 [==============================] - 0s 922us/step - loss: 0.2670 - accuracy: 0.9272\n",
      "Test accuracy: 0.9272000193595886\n"
     ]
    }
   ],
   "source": [
    "# Define EarlyStopping callback\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    min_delta=0.001, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model with EarlyStopping callback\n",
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edfa9f",
   "metadata": {},
   "source": [
    "We can see that it stops in the epoch 13 because in 3 consecutives epochs the validation accuracy did not improve (0.2735 -> 0.2826 -> 0.2763)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d55a08",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"><a/>\n",
    "### Learning Rate Scheduler\n",
    "\n",
    "The Learning Rate Scheduler callback in TensorFlow allows you to dynamically adjust the learning rate during training based on predefined schedules or functions. It helps optimize the training process by allowing the model to converge faster and potentially achieve better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acedd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b39646f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 2.7012 - accuracy: 0.7847 - val_loss: 2.9506 - val_accuracy: 0.8246 - lr: 0.1000\n",
      "Epoch 2/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.1615 - accuracy: 0.8035 - val_loss: 2.9053 - val_accuracy: 0.8268 - lr: 0.1000\n",
      "Epoch 3/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.1910 - accuracy: 0.8090 - val_loss: 4.0559 - val_accuracy: 0.8019 - lr: 0.1000\n",
      "Epoch 4/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.0937 - accuracy: 0.8156 - val_loss: 4.4215 - val_accuracy: 0.7731 - lr: 0.1000\n",
      "Epoch 5/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.3387 - accuracy: 0.8122 - val_loss: 3.5317 - val_accuracy: 0.8326 - lr: 0.1000\n",
      "Epoch 6/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8352 - accuracy: 0.8987 - val_loss: 0.5338 - val_accuracy: 0.9024 - lr: 0.0100\n",
      "Epoch 7/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4316 - accuracy: 0.9011 - val_loss: 0.4344 - val_accuracy: 0.9042 - lr: 0.0100\n",
      "Epoch 8/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3978 - accuracy: 0.9044 - val_loss: 0.4401 - val_accuracy: 0.9030 - lr: 0.0100\n",
      "Epoch 9/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3807 - accuracy: 0.9066 - val_loss: 0.4630 - val_accuracy: 0.8978 - lr: 0.0100\n",
      "Epoch 10/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3643 - accuracy: 0.9085 - val_loss: 0.4118 - val_accuracy: 0.9037 - lr: 0.0100\n",
      "Epoch 11/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2662 - accuracy: 0.9307 - val_loss: 0.3275 - val_accuracy: 0.9185 - lr: 0.0010\n",
      "Epoch 12/12\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2567 - accuracy: 0.9313 - val_loss: 0.3196 - val_accuracy: 0.9199 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Define a simple learning rate schedule function\n",
    "#In this example, we use a simple decay schedule where \n",
    "#the learning rate decreases by a factor of 0.1 every 5 epochs.\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a learning rate based on the current epoch.\n",
    "    \"\"\"\n",
    "    initial_lr = 0.1\n",
    "    decay_factor = 0.1\n",
    "    decay_epochs = 5\n",
    "    lr = initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "    return lr\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "# Train the model with the learning rate scheduler callback\n",
    "history = model.fit(x_train, y_train, epochs=12,\n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d5909",
   "metadata": {},
   "source": [
    "We can see that when it reaches epoch 6 (after 5 epochs), the learning rate changes from 0.1 to 0.01, and when it reaches epoch 11 (after another 5 epochs), from 0.01 to 0.001.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0dbed6",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### Tensor Board callback\n",
    "\n",
    "The TensorBoard callback in TensorFlow is used to visualize and monitor the training process of your neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4a906bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4565 - accuracy: 0.8756 - val_loss: 0.2929 - val_accuracy: 0.9176\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2928 - accuracy: 0.9176 - val_loss: 0.2782 - val_accuracy: 0.9188\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2774 - accuracy: 0.9225 - val_loss: 0.2680 - val_accuracy: 0.9245\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2691 - accuracy: 0.9252 - val_loss: 0.2724 - val_accuracy: 0.9257\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2649 - accuracy: 0.9268 - val_loss: 0.2685 - val_accuracy: 0.9252\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2608 - accuracy: 0.9281 - val_loss: 0.2713 - val_accuracy: 0.9258\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2572 - accuracy: 0.9288 - val_loss: 0.2829 - val_accuracy: 0.9209\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2559 - accuracy: 0.9290 - val_loss: 0.2714 - val_accuracy: 0.9248\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2536 - accuracy: 0.9292 - val_loss: 0.2694 - val_accuracy: 0.9255\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2526 - accuracy: 0.9302 - val_loss: 0.2803 - val_accuracy: 0.9245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd6a26a2da0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "# Define TensorBoard callback\n",
    "# We specify yhe log directory where the TensorBoard logs will be saved. The log directory includes \n",
    "# a timestamp to make it unique.\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with TensorBoard callback\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa87e92",
   "metadata": {},
   "source": [
    "\n",
    "After training, you can start TensorBoard from the command line by navigating to the directory containing your code and logs:\n",
    "\n",
    ".....Predefined$ ls\n",
    "\n",
    "\n",
    "'Callbacks.ipnyb' logs\n",
    "\n",
    "Start Tensor Board\n",
    "\n",
    "...... Predefined$ tensorboard --logdir logs/\n",
    "\n",
    "\n",
    "Then, we navigate to 'http://localhost:6006'\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"images/TensorBoard.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7d6bf",
   "metadata": {},
   "source": [
    "<a name=\"4.4\"></a>\n",
    "### Checkpoint \n",
    "\n",
    "The Checkpoint callback allows you to save the model's weights during training, which enables you to resume training from the last saved checkpoint or use the saved weights for inference later on. This callback is particularly useful in scenarios where you have long training times or when you want to track the progress of your model over multiple training sessions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46882984",
   "metadata": {},
   "source": [
    "We are going to simulate a scenario where the training is interrupted (for example, if the computer crashes) to demonstrate how we can resume training not from the beginning, but from the last saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c299b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9310INFO:tensorflow:Assets written to: training/model_checkpoint.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/model_checkpoint.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2507 - accuracy: 0.9310 - val_loss: 0.2721 - val_accuracy: 0.9251\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2498 - accuracy: 0.9305 - val_loss: 0.2735 - val_accuracy: 0.9249\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2485 - accuracy: 0.9315 - val_loss: 0.2814 - val_accuracy: 0.9225\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2471 - accuracy: 0.9312 - val_loss: 0.2729 - val_accuracy: 0.9257\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2465 - accuracy: 0.9320 - val_loss: 0.2725 - val_accuracy: 0.9267\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2460 - accuracy: 0.9313 - val_loss: 0.2753 - val_accuracy: 0.9254\n",
      "Epoch 7/20\n",
      "1353/1875 [====================>.........] - ETA: 0s - loss: 0.2417 - accuracy: 0.9334"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39mcheckpoint_path,\n\u001b[1;32m     10\u001b[0m                                       monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                       save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# only saves the best\u001b[39;00m\n\u001b[1;32m     12\u001b[0m                                       mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# it's min because monitor=val_loss\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model with checkpoint callback\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    231\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict:\n\u001b[0;32m---> 48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary[(context, dispatch_type)]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:80\u001b[0m, in \u001b[0;36mTypeDispatchTable.dispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the most specific supertype target if it exists in the table.\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# For known exact matches.\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_table\u001b[49m:\n\u001b[1;32m     81\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m request\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# For known non-exact matches.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# (self._dispatch cache does not contain exact matches)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:456\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:155\u001b[0m, in \u001b[0;36mParameter.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/type_spec.py:555\u001b[0m, in \u001b[0;36mTypeSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 555\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py:895\u001b[0m, in \u001b[0;36mDenseSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "# Define checkpoint callback to save model weights\n",
    "checkpoint_path = \"training/model_checkpoint.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "checkpoint_callback = callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                      monitor='val_loss',\n",
    "                                      save_best_only=True, # only saves the best\n",
    "                                      mode='min') # it's min because monitor=val_loss\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with checkpoint callback\n",
    "model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f13a8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_ckp = load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "598d2cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 953us/step - loss: 0.2721 - accuracy: 0.9251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27205604314804077, 0.9251000285148621]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "model_ckp.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26689e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2488 - accuracy: 0.9312 - val_loss: 0.2724 - val_accuracy: 0.9235\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2484 - accuracy: 0.9314 - val_loss: 0.2722 - val_accuracy: 0.9262\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2481 - accuracy: 0.9315 - val_loss: 0.2763 - val_accuracy: 0.9264\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2467 - accuracy: 0.9313 - val_loss: 0.2763 - val_accuracy: 0.9263\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2460 - accuracy: 0.9311 - val_loss: 0.2759 - val_accuracy: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd69d169150>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resume training\n",
    "model_ckp.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e70c829",
   "metadata": {},
   "source": [
    "<a name=\"4.5\"></a>\n",
    "### Combining callbacks\n",
    "\n",
    "We can combine callbacks. In the following example, we combine 'Early Stopping' with 'Learning Rate Scheduler'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e649538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8128108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 3.0866 - accuracy: 0.7808 - val_loss: 3.2225 - val_accuracy: 0.8380 - lr: 0.1000\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.3037 - accuracy: 0.8058 - val_loss: 2.0044 - val_accuracy: 0.8497 - lr: 0.1000\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 2.9575 - accuracy: 0.8112 - val_loss: 3.7519 - val_accuracy: 0.7789 - lr: 0.1000\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.2227 - accuracy: 0.8120 - val_loss: 3.8988 - val_accuracy: 0.8007 - lr: 0.1000\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 3.3476 - accuracy: 0.8130 - val_loss: 3.9876 - val_accuracy: 0.8066 - lr: 0.1000\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7884 - accuracy: 0.8975 - val_loss: 0.5049 - val_accuracy: 0.9004 - lr: 0.0100\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4386 - accuracy: 0.9016 - val_loss: 0.4862 - val_accuracy: 0.8995 - lr: 0.0100\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3939 - accuracy: 0.9064 - val_loss: 0.4495 - val_accuracy: 0.9006 - lr: 0.0100\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3761 - accuracy: 0.9050 - val_loss: 0.4500 - val_accuracy: 0.8974 - lr: 0.0100\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3654 - accuracy: 0.9062 - val_loss: 0.4356 - val_accuracy: 0.8991 - lr: 0.0100\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2649 - accuracy: 0.9302 - val_loss: 0.3247 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2559 - accuracy: 0.9303 - val_loss: 0.3248 - val_accuracy: 0.9185 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2535 - accuracy: 0.9306 - val_loss: 0.3203 - val_accuracy: 0.9217 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2518 - accuracy: 0.9305 - val_loss: 0.3204 - val_accuracy: 0.9193 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2503 - accuracy: 0.9312 - val_loss: 0.3239 - val_accuracy: 0.9164 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2421 - accuracy: 0.9335 - val_loss: 0.3111 - val_accuracy: 0.9220 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2403 - accuracy: 0.9344 - val_loss: 0.3090 - val_accuracy: 0.9234 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2399 - accuracy: 0.9343 - val_loss: 0.3099 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2397 - accuracy: 0.9341 - val_loss: 0.3082 - val_accuracy: 0.9220 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2395 - accuracy: 0.9349 - val_loss: 0.3101 - val_accuracy: 0.9232 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Define EarlyStopping callback\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    min_delta=0.001, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# LR Scheduler\n",
    "# This function keeps the initial learning rate for the first 5 epochs\n",
    "# and decreases it exponentially after that.\n",
    "def scheduler(epoch, lr):\n",
    "     if epoch < 3:\n",
    "        return lr\n",
    "     else:\n",
    "        return lr * ops.exp(-0.1)\n",
    "\n",
    "\n",
    "    \n",
    "lr_schduler = callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    \n",
    "# Train the model with EarlyStopping callback\n",
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e679b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
